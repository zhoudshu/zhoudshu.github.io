<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Zhoudshu's Blog</title><link href="http://zhoudshu.github.io/" rel="alternate"></link><link href="http://zhoudshu.github.io/feeds/zhoudshu.atom.xml" rel="self"></link><id>http://zhoudshu.github.io/</id><updated>2017-06-19T21:15:00+08:00</updated><entry><title>I had successed to finish the machine learning lessons at July 19</title><link href="http://zhoudshu.github.io/blog/I-had-successed-to-finish-the-machine=learning-lessons=at=july-19/" rel="alternate"></link><published>2017-06-19T21:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2017-06-19:blog/I-had-successed-to-finish-the-machine=learning-lessons=at=july-19/</id><summary type="html">&lt;h1 id="content"&gt;Content&lt;/h1&gt;
&lt;p&gt;I spent about two months on learning &lt;a href="https://www.coursera.org/learn/machine-learning/home/welcome"&gt;&lt;strong&gt;machine learning video&lt;/strong&gt;&lt;/a&gt;. Finally, I passed the lessions. This Result is the following. &lt;img alt="Result" src="http://zhoudshu.github.io/images/machinelearning-congratulation.jpg" /&gt;, &lt;img alt="Grade" src="http://zhoudshu.github.io/images/machinelearning-grade.jpg" /&gt;.&lt;/p&gt;
&lt;h2 id="good-luck"&gt;Good luck&lt;/h2&gt;</summary><category term="machinelearning"></category><category term="andrewng"></category><category term="video"></category></entry><entry><title>Some tips for configing the flume properties</title><link href="http://zhoudshu.github.io/blog/Some-tips-for-configing-the-flume-prpperties/" rel="alternate"></link><published>2017-05-25T21:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2017-05-25:blog/Some-tips-for-configing-the-flume-prpperties/</id><summary type="html">&lt;h1 id="the-tips"&gt;The Tips&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://flume.apache.org/"&gt;&lt;strong&gt;Flume&lt;/strong&gt;&lt;/a&gt; is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.I already have installed many flume systems to collect streaming log data. But I found some problems when we used flume. I write this blog to record the problems and solutions. and anybody else will avoid such problem.&lt;/p&gt;
&lt;h2 id="the-running-environment"&gt;The running environment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CDH version 5.8.0+&lt;/li&gt;
&lt;li&gt;Flume 1.6.0+&lt;/li&gt;
&lt;li&gt;Java 1.7.0+&lt;/li&gt;
&lt;li&gt;Linux 2.6.32-573.el6.x86_6&lt;/li&gt;
&lt;li&gt;Centos 6.6+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="tips-one-rotating-invalid"&gt;Tips one :rotating invalid&lt;/h2&gt;
&lt;p&gt;flume by using the following configuration uploads and rotates files to hadoop ...&lt;/p&gt;</summary><category term="Flume"></category><category term="CDH"></category><category term="Centos"></category></entry><entry><title>Why does linux du command print no result and occupy one 100 CPU usage</title><link href="http://zhoudshu.github.io/blog/Why-does-linux-du-command-print-no-result-and-occupy-one-100-CPU-usage/" rel="alternate"></link><published>2017-05-24T21:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2017-05-24:blog/Why-does-linux-du-command-print-no-result-and-occupy-one-100-CPU-usage/</id><summary type="html">&lt;h2 id="the-problem"&gt;The Problem&lt;/h2&gt;
&lt;p&gt;Today, My colleague found an abnormal problem and asked me the reason. I recorded the following analysis steps. &lt;/p&gt;
&lt;p&gt;This problem is that linux du command does not print the results, and at the same time, the process of du command occupies 100% CPU usage. Result of top command is the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;# top&lt;/span&gt;
  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                                                                                    
&lt;span class="m"&gt;36343&lt;/span&gt; root      &lt;span class="m"&gt;20&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;  110m  13m &lt;span class="m"&gt;1780&lt;/span&gt; R 99.8  0.0   1:37.66 du                                                                                                         
&lt;span class="m"&gt;36370&lt;/span&gt; root      &lt;span class="m"&gt;20&lt;/span&gt;   &lt;span class="m"&gt;0&lt;/span&gt;  110m  13m &lt;span class="m"&gt;1780&lt;/span&gt; R 94.2  0.0   1:20.98 du
   &lt;span class="m"&gt;86&lt;/span&gt; root ...&lt;/pre&gt;&lt;/div&gt;</summary><category term="du"></category><category term="mtab"></category><category term="bind"></category><category term="Linux"></category><category term="Centos"></category></entry><entry><title>How to upgrade the tomcat version used by CDH httpFs service</title><link href="http://zhoudshu.github.io/blog/How-to-upgrade-the-tomcat-version-used-by-CDH-httpFs-service/" rel="alternate"></link><published>2017-04-06T21:45:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2017-04-06:blog/How-to-upgrade-the-tomcat-version-used-by-CDH-httpFs-service/</id><summary type="html">&lt;h1 id="the-problem"&gt;The Problem&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://tomcat.apache.org/security-6.html"&gt;&lt;strong&gt;Tomcat&lt;/strong&gt;&lt;/a&gt; released one patch which fixed one error bug about CVE-2016-8745. In my CDH cluster, httpFS service is used by web http service, and it is run by 6.0.44 version Tomcat. We must upgrade the tomcat version from 6.0.44 to 6.0.50+ avoid of security attacking.&lt;/p&gt;
&lt;h2 id="the-cdh-envirenment"&gt;the CDH Envirenment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CDH version 5.7.0+&lt;/li&gt;
&lt;li&gt;Java 1.7.0+&lt;/li&gt;
&lt;li&gt;Linux 2.6.32-573.el6.x86_6&lt;/li&gt;
&lt;li&gt;Centos 6.6+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="the-upgrade-steps"&gt;The upgrade steps&lt;/h2&gt;
&lt;h3 id="download-the-newest-version-of-tomcat"&gt;Download the newest version of tomcat&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://mirror.bit.edu.cn/apache/tomcat/tomcat-6/v6.0.53/bin/apache-tomcat-6.0.53.tar.gz"&gt;&lt;strong&gt;Tomcat version 6.0.53&lt;/strong&gt;&lt;/a&gt; can be downloaded. I can extract gz package&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;tar xvfz apache-tomcat-6.0 ...&lt;/pre&gt;&lt;/div&gt;</summary><category term="Tomcat"></category><category term="CDH"></category><category term="HttpFs"></category><category term="security"></category><category term="Bug"></category></entry><entry><title>How to limit virtual memory using of Flume process in Centos 6.x</title><link href="http://zhoudshu.github.io/blog/How-to-limit-virtual-memory-using-of-Flume-process-in-CentOs-6.x/" rel="alternate"></link><published>2017-04-06T21:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2017-04-06:blog/How-to-limit-virtual-memory-using-of-Flume-process-in-CentOs-6.x/</id><summary type="html">&lt;h1 id="the-problem"&gt;The Problem&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://flume.apache.org/"&gt;&lt;strong&gt;Flume&lt;/strong&gt;&lt;/a&gt; is a distributed, reliable, and available service for efficiently collecting, aggregating, and moving large amounts of log data.I already have installed many flume systems to collect streaming log data. But I found one problem that flume process was occuping more virtual memories and fewer physical memories. Why is this situation occurred? This blog explains and provides the methods to solve this problem. &lt;/p&gt;
&lt;h2 id="the-running-environment"&gt;The running environment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CDH version 5.8.0+&lt;/li&gt;
&lt;li&gt;Flume 1.6.0+&lt;/li&gt;
&lt;li&gt;Java 1.7.0+&lt;/li&gt;
&lt;li&gt;Linux 2.6.32-573.el6.x86_6&lt;/li&gt;
&lt;li&gt;Centos 6.6+&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="the-top-command-result-of-flume-process"&gt;The Top command Result of flume process&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="m"&gt;26963&lt;/span&gt; root ...&lt;/pre&gt;&lt;/div&gt;</summary><category term="Flume"></category><category term="CDH"></category><category term="virtual"></category><category term="Memory"></category><category term="Centos"></category></entry><entry><title>How to config and query Impala SQL interface of CDH with kerberos mechanism</title><link href="http://zhoudshu.github.io/blog/How-to-config-and-impala-sql-interface-with-kerberos/" rel="alternate"></link><published>2017-02-23T21:55:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2017-02-23:blog/How-to-config-and-impala-sql-interface-with-kerberos/</id><summary type="html">&lt;h1 id="the-problem"&gt;The Problem&lt;/h1&gt;
&lt;p&gt;Recently, I have spended several days on rearching impala sql interface with security mechanism. There are two methods to query impala data. One is the kerberos mechanism, the other is ldap method which provided user and password. The first one is very difficult and usually adapted for internal using in the hadoop cluster, So I choose the ldap method for external appliction such as jdbc interface. This blog provides the configuration steps and queries demo for using ldap to impala databases. &lt;/p&gt;
&lt;h2 id="the-test-environment"&gt;The test environment&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;CDH version 5.8.0+&lt;/li&gt;
&lt;li&gt;kerberos software&lt;/li&gt;
&lt;li&gt;ldap service&lt;/li&gt;
&lt;li&gt;Linux 2.6.32-573.el6 ...&lt;/li&gt;&lt;/ul&gt;</summary><category term="Impala"></category><category term="CDH"></category><category term="kerberos"></category><category term="SQL"></category><category term="ldap"></category></entry><entry><title>Flume must be used the hadoop native libraries when uploading gz file</title><link href="http://zhoudshu.github.io/blog/Flume-must-be-used-the-hadoop-native-libraries/" rel="alternate"></link><published>2016-12-27T18:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2016-12-27:blog/Flume-must-be-used-the-hadoop-native-libraries/</id><summary type="html">&lt;h1 id="the-problem"&gt;THe Problem&lt;/h1&gt;
&lt;p&gt;Recently, I had been one requirement in my project for uploading real-time log record into hadoop cluster. I chose the open source software &lt;a href="https://flume.apache.org/"&gt;&lt;strong&gt;Flume&lt;/strong&gt;&lt;/a&gt;. After installing flume, The log record could be transferred to hadoop cluster with gz suffix successfully. But I found the gz file size more than decompressed one. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root   root        &lt;span class="m"&gt;942&lt;/span&gt; Dec &lt;span class="m"&gt;27&lt;/span&gt; 17:28 ngaancache-access.log.2016122321.1482498035352
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; root   root       &lt;span class="m"&gt;6571&lt;/span&gt; Dec &lt;span class="m"&gt;27&lt;/span&gt; 17:32 ngaancache-access.log.2016122321.1482498035352.gz
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;When I used gzip command to decompress this file, one warning infomation "trailing garbage ignored" is reported as followed&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="c1"&gt;#gzip ...&lt;/span&gt;&lt;/pre&gt;&lt;/div&gt;</summary><category term="Flume"></category><category term="hadoop"></category><category term="gzip"></category><category term="compress"></category><category term="native"></category></entry><entry><title>Howto Run SSL splitting and Caching Web proxies Demo</title><link href="http://zhoudshu.github.io/blog/Howto-Run-SSL-splitting-and-Caching-Web-proxies-Demo/" rel="alternate"></link><published>2016-06-13T22:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2016-06-13:blog/Howto-Run-SSL-splitting-and-Caching-Web-proxies-Demo/</id><summary type="html">&lt;h1 id="barnraising"&gt;barnraising&lt;/h1&gt;
&lt;p&gt;This Project is provided by Chris Lesniewski-Laas and M. Frans Kaashoek for reducing the bandwidth load on Web servers. the thesis is public and Demo Program is open source code. We can access &lt;a href="https://pdos.csail.mit.edu/papers/ssl-splitting-usenixsecurity03/"&gt;&lt;strong&gt;thesis&lt;/strong&gt;&lt;/a&gt; and download the &lt;a href="https://pdos.lcs.mit.edu/archive/barnraising/"&gt;&lt;strong&gt;Demo&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But both thesis and demo have not specific installed document. I had met a lot of problems, sometimes I had to modify the source code. After 3 weeks later, I finally install and run successfully. I wrote the process of installing to this file, and this git reposity is my modified and successful barnraising version. My modified Version of Barnraising is ...&lt;/p&gt;</summary><category term="SSL"></category><category term="Cache"></category><category term="Proxy"></category><category term="Barnraising"></category><category term="Broker"></category></entry><entry><title>Howto Stop Bind writing log to system messages</title><link href="http://zhoudshu.github.io/blog/Howto-Stop-Bind-writing-system-log-to-messages/" rel="alternate"></link><published>2016-06-13T20:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2016-06-13:blog/Howto-Stop-Bind-writing-system-log-to-messages/</id><summary type="html">&lt;p&gt;&lt;a href="https://www.isc.org/downloads/bind/"&gt;&lt;strong&gt;Bind&lt;/strong&gt;&lt;/a&gt; is open source software that implements the Domain Name System (DNS) protocols for the Internet, Many Companies have used it. This article discusses the logging function of Bind. by default configuration, Bind writes logging to Linux system messages in /var/log/messages directory like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt; Jun 13 10:10:09 Test_Host named[19304]: success resolving &amp;#39;ns4.servodns.com/A&amp;#39; (in &amp;#39;servodns.com&amp;#39;?) after reducing the advertised EDNS UDP packet size to 512 octets
 Jun 13 10:10:09 Test_Host named[19304]: success resolving &amp;#39;ns4.servodns.com/AAAA&amp;#39; (in &amp;#39;servodns.com&amp;#39;?) after reducing the advertised EDNS UDP packet size to 512 ...&lt;/pre&gt;&lt;/div&gt;</summary><category term="Bind"></category><category term="DNS"></category><category term="Logging"></category><category term="syslogd"></category><category term="messages"></category></entry><entry><title>How I built this Blog using Pelican</title><link href="http://zhoudshu.github.io/how-to/how-i-built-this-blog/" rel="alternate"></link><published>2016-05-19T11:15:00+08:00</published><author><name>zhoudshu</name></author><id>tag:zhoudshu.github.io,2016-05-19:how-to/how-i-built-this-blog/</id><summary type="html">&lt;p&gt;I have wanted to run a personal blog for a long time. Because I am family with Python, thus, I am prior to choose python blog framework. At first I chosed the &lt;a href="http://mezzanine.jupo.org"&gt;&lt;strong&gt;mezzanine&lt;/strong&gt;&lt;/a&gt; which is best Django CMS. I installed this system and had used it for several weeks. I find that this system is not easy to be installed, managed, maintained, migrated, furthemore, it is slowly accessed for saving data to database.&lt;/p&gt;
&lt;p&gt;Finally I finded the static blog technology by &lt;a href="https://www.staticgen.com"&gt;staicgen WebSite&lt;/a&gt;. I choose the Python Language system Pelican which is the best Python tool for static blog&lt;/p&gt;
&lt;h2 id="what-is-pelican"&gt;What ...&lt;/h2&gt;</summary><category term="how-to"></category><category term="python"></category><category term="pelican"></category><category term="blog"></category><category term="website"></category></entry></feed>